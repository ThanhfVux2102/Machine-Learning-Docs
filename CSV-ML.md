# ğŸ“ Tutorial: Machine Learning Pipeline with Scikitâ€‘learn

## 1) Data Splitting

### `train_test_split` (from `sklearn.model_selection`)
Chia dá»¯ liá»‡u thÃ nh táº­p **train** vÃ  **test**.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```
- **`test_size`**: tá»· lá»‡ dá»¯ liá»‡u test (vÃ­ dá»¥: `0.2` = 20%).
- **`random_state`**: seed cá»‘ Ä‘á»‹nh, Ä‘áº£m báº£o tÃ¡i láº­p káº¿t quáº£.
- **`stratify`**: náº¿u = `y`, giá»¯ Ä‘Ãºng tá»· lá»‡ nhÃ£n khi chia train/test.

---

## 2) Data Normalization / Scaling

Chuáº©n hoÃ¡ dá»¯ liá»‡u sá»‘ giÃºp mÃ´ hÃ¬nh há»™i tá»¥ nhanh hÆ¡n vÃ  trÃ¡nh viá»‡c feature cÃ³ thang Ä‘o lá»›n láº¥n Ã¡t feature khÃ¡c.

**PhÆ°Æ¡ng phÃ¡p phá»• biáº¿n:**
- `StandardScaler`: chuáº©n hoÃ¡ vá» mean=0, std=1.
- `MinMaxScaler`: Ä‘Æ°a dá»¯ liá»‡u vá» [0, 1].
- `RobustScaler`: bá»n vá»›i outliers (dá»±a trÃªn median & IQR).
- `Normalizer`: chuáº©n hoÃ¡ theo vector norm (L1/L2) trÃªn tá»«ng hÃ ng (máº«u).

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer
```

---

## 3) Encoding (Categorical Features)

Biáº¿n Ä‘á»•i dá»¯ liá»‡u dáº¡ng chuá»—i thÃ nh sá»‘:

- `OneHotEncoder`: táº¡o dummy variables (0/1) cho tá»«ng háº¡ng má»¥c.
- `LabelEncoder`: Ã¡nh xáº¡ háº¡ng má»¥c â†’ sá»‘ nguyÃªn (chá»§ yáº¿u dÃ¹ng cho **target**).
- `OrdinalEncoder`: gÃ¡n sá»‘ theo thá»© tá»± (small < medium < large).
- Target Encoding (ngoÃ i sklearn â€“ dÃ¹ng `category_encoders`).

```python
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder
```

---

## 4) ColumnTransformer

Káº¿t há»£p nhiá»u bÆ°á»›c xá»­ lÃ½ cho tá»«ng loáº¡i cá»™t trong **má»™t** Ä‘á»‘i tÆ°á»£ng.

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

numeric_features = [...]      # vÃ­ dá»¥: ['Total Cases','Total Deaths',...]
categorical_features = [...]  # vÃ­ dá»¥: ['Region']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features),
    ],
    remainder='drop'  # hoáº·c 'passthrough' náº¿u muá»‘n giá»¯ láº¡i cá»™t khÃ¡c
)
```

---

## 5) Model Options

### a) Classification
- `SGDClassifier(loss="log_loss")` â€“ Logistic Regression vá»›i Gradient Descent.
- `LogisticRegression`
- `RandomForestClassifier`
- `SVC`
- `KNeighborsClassifier`

### b) Regression
- `SGDRegressor`
- `LinearRegression`
- `RandomForestRegressor`
- `SVR`
- `KNeighborsRegressor`

---

## 6) Pipeline

Gom táº¥t cáº£ bÆ°á»›c láº¡i Ä‘á»ƒ trÃ¡nh rÃ² rá»‰ dá»¯ liá»‡u vÃ  code gá»n hÆ¡n.

```python
from sklearn.pipeline import Pipeline
from sklearn.linear_model import SGDClassifier

clf = Pipeline(steps=[
    ('preprocess', preprocessor),
    ('classifier', SGDClassifier(loss="log_loss", max_iter=1000, tol=1e-3, random_state=42))
])
```

---

## 7) Evaluation Metrics

### Classification
```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

y_pred = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
```

### Regression
```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

y_pred = reg.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R2:", r2_score(y_test, y_pred))
```

### Visualization (Confusion Matrix)
```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()
```

---

## 8) Handling Missing Values (2 cÃ¡ch chÃ­nh)

### CÃ¡ch A â€“ **Loáº¡i bá»** (Deletion)
DÃ¹ng khi dá»¯ liá»‡u thiáº¿u ráº¥t Ã­t hoáº·c cá»™t/hÃ ng khÃ´ng quan trá»ng.
```python
# XoÃ¡ hÃ ng cÃ³ báº¥t ká»³ NaN
df_drop_rows = df.dropna()

# XoÃ¡ cá»™t thiáº¿u quÃ¡ nhiá»u (vÃ­ dá»¥ > 40%)
thresh = int(0.6 * len(df))       # giá»¯ cá»™t cÃ³ >= 60% giÃ¡ trá»‹
df_drop_cols = df.dropna(axis=1, thresh=thresh)
```

### CÃ¡ch B â€“ **Äiá»n giÃ¡ trá»‹** (Imputation)
Giá»¯ láº¡i tá»‘i Ä‘a dá»¯ liá»‡u, phÃ¹ há»£p vá»›i Worldometer.
```python
from sklearn.impute import SimpleImputer
import numpy as np

# Tá»± Ä‘á»™ng tÃ¡ch loáº¡i cá»™t
num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()
cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()

# Äiá»n cho numeric: median (Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outlier)
df[num_cols] = SimpleImputer(strategy='median').fit_transform(df[num_cols])

# Äiá»n cho categorical: most_frequent
if len(cat_cols) > 0:
    df[cat_cols] = SimpleImputer(strategy='most_frequent').fit_transform(df[cat_cols])

# Kiá»ƒm tra cÃ²n thiáº¿u khÃ´ng
print(df.isnull().sum().sort_values(ascending=False).head(10))
```

> LÆ°u Ã½: Vá»›i cÃ¡c cá»™t Ä‘á»‹nh danh nhÆ° `Country`, thÆ°á»ng **khÃ´ng dÃ¹ng lÃ m feature**; náº¿u dÃ¹ng `Region/Continent` thÃ¬ cáº§n Oneâ€‘Hot Encoding.

---

## 9) Correlation Matrix & Heatmap (Ä‘á»ƒ chá»n lá»c Ä‘áº·c trÆ°ng)

DÃ¹ng Ä‘á»ƒ phÃ¡t hiá»‡n:
- Feature tÆ°Æ¡ng quan máº¡nh/yáº¿u vá»›i nhÃ£n (`DeathRate` hoáº·c `DeathRateCategory`).
- Cáº·p features tÆ°Æ¡ng quan quÃ¡ cao vá»›i nhau â†’ cÃ¢n nháº¯c giá»¯ má»™t Ä‘á»ƒ giáº£m trÃ¹ng láº·p.

```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# VÃ­ dá»¥ táº¡o nhÃ£n liÃªn tá»¥c vÃ  phÃ¢n lá»›p
df['DeathRate'] = df['Total Deaths'] / df['Total Cases']
def categorize(rate):
    if rate < 0.01: return 0
    elif rate < 0.03: return 1
    return 2
df['DeathRateCategory'] = df['DeathRate'].apply(categorize)

# Ma tráº­n tÆ°Æ¡ng quan cho numeric + DeathRate
num_for_corr = df.select_dtypes(include=['int64','float64']).columns.tolist()
corr = df[num_for_corr + ['DeathRate']].corr(method='pearson')

plt.figure(figsize=(12,8))
sns.heatmap(corr, cmap='coolwarm', center=0)
plt.title('Correlation heatmap')
plt.show()
```

**Gá»£i Ã½ chá»n lá»c feature:**
- Giá»¯ feature cÃ³ |corr vá»›i `DeathRate` cao.
- Loáº¡i 1 trong 2 feature náº¿u chÃºng tÆ°Æ¡ng quan ráº¥t cao (vÃ­ dá»¥ |corr| > 0.9).
- TrÃ¡nh Ä‘Æ°a cá»™t Ä‘Ã£ tÃ­nh sáºµn theo Ä‘áº§u ngÆ°á»i (`Tot Cases/1M pop`, `Deaths/1M pop`, `Tests/1M pop`) náº¿u Ä‘Ã£ cÃ³ tá»•ng sá»‘ tÆ°Æ¡ng á»©ng, Ä‘á»ƒ giáº£m multicollinearity.

---

## 10) TÃ³m táº¯t nhanh
- **Splitting**: `train_test_split` (nhá»› `stratify=y` cho bÃ i toÃ¡n phÃ¢n lá»›p máº¥t cÃ¢n báº±ng).
- **Missing values**: Æ°u tiÃªn **Imputation** (median / most_frequent); chá»‰ xoÃ¡ khi thiáº¿u quÃ¡ Ã­t.
- **Scaling**: `StandardScaler` cho numeric (Ä‘áº·c biá»‡t khi tá»‘i Æ°u báº±ng Gradient Descent).
- **Encoding**: `OneHotEncoder` cho categorical (náº¿u dÃ¹ng).
- **Feature selection**: dÃ¹ng **correlation matrix + heatmap** vÃ /hoáº·c `SelectKBest`, `RFE`.
- **Evaluation**: `accuracy`, `confusion_matrix`, `classification_report` cho classification.

